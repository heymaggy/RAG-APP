{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e04e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.4)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community sentence-transformers chromadb langchain-google-genai pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eff08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data prepared into knowledge chunks.\n",
      "ðŸ§  Initializing embedding model and vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/snf6g1r515730s7chny_jm3m0000gn/T/ipykernel_61958/3388546220.py:54: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/deliciamagdaline/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/deliciamagdaline/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/deliciamagdaline/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 397, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 752, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lt/snf6g1r515730s7chny_jm3m0000gn/T/ipykernel_61958/3388546220.py\", line 54, in <module>\n",
      "    embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py\", line 222, in warn_if_direct_instance\n",
      "    return wrapped(self, *args, **kwargs)\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/langchain_community/embeddings/huggingface.py\", line 84, in __init__\n",
      "    import sentence_transformers\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/sentence_transformers/__init__.py\", line 10, in <module>\n",
      "    from sentence_transformers.backend import (\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/sentence_transformers/backend.py\", line 11, in <module>\n",
      "    from sentence_transformers.util import disable_datasets_caching, is_datasets_available\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/sentence_transformers/util.py\", line 20, in <module>\n",
      "    import torch\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/deliciamagdaline/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ§  Initializing embedding model and vector store...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m embedding_function = SentenceTransformerEmbeddings(model_name=\u001b[33m\"\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m vectorstore = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknowledge_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m retriever = vectorstore.as_retriever(search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m}) \u001b[38;5;66;03m# This will retrieve the top 2 most relevant chunks.\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Vector store is ready.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m    838\u001b[39m         api=chroma_collection._client,\n\u001b[32m    839\u001b[39m         ids=ids,\n\u001b[32m    840\u001b[39m         metadatas=metadatas,\n\u001b[32m    841\u001b[39m         documents=texts,\n\u001b[32m    842\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:277\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    281\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/langchain_community/embeddings/huggingface.py:115\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    113\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings.tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1110\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m             all_embeddings = np.asarray([emb.float().numpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[32m   1109\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1110\u001b[39m             all_embeddings = np.asarray(\u001b[43m[\u001b[49m\u001b[43memb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np.ndarray):\n\u001b[32m   1112\u001b[39m     all_embeddings = [torch.from_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/faers_menstrual_rag_project/venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1110\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1108\u001b[39m             all_embeddings = np.asarray([emb.float().numpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[32m   1109\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1110\u001b[39m             all_embeddings = np.asarray([\u001b[43memb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np.ndarray):\n\u001b[32m   1112\u001b[39m     all_embeddings = [torch.from_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# --- 1. Install the necessary libraries ---\n",
    "# You only need to run this cell once.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "from getpass import getpass\n",
    "\n",
    "# --- 2. Set up your Google API Key ---\n",
    "# LangChain will use this key to talk to the Gemini model.\n",
    "# Get your key from Google AI Studio: https://makersuite.google.com/app/apikey\n",
    "if 'GOOGLE_API_KEY' not in os.environ:\n",
    "    os.environ['GOOGLE_API_KEY'] = getpass(\"Enter your Google API Key: \")\n",
    "\n",
    "\n",
    "# --- 3. Prepare Your Data (The part you already know!) ---\n",
    "# We create our sample CSV data and convert the rows into text chunks.\n",
    "csv_data = \"\"\"Report_ID,Drug_Name,Adverse_Event,Patient_Age,Description\n",
    "FAERS-001,Sertraline,Amenorrhea,28,\"Patient experienced a loss of menstrual cycle after three months on Sertraline.\"\n",
    "FAERS-002,Ibuprofen,Headache,45,\"Standard headache reported after taking Ibuprofen for a fever.\"\n",
    "FAERS-003,Apixaban,Menorrhagia,52,\"Patient reported unusually heavy and prolonged menstrual bleeding (menorrhagia).\"\n",
    "FAERS-004,Sertraline,Insomnia,34,\"Patient had difficulty sleeping after starting the medication.\"\n",
    "FAERS-005,Sertraline,Amenorrhea,31,\"Second report of amenorrhea linked to Sertraline, cycle returned after stopping treatment.\"\n",
    "\"\"\"\n",
    "df = pd.read_csv(io.StringIO(csv_data))\n",
    "\n",
    "knowledge_chunks = []\n",
    "for index, row in df.iterrows():\n",
    "    chunk = (\n",
    "        f\"In report {row['Report_ID']}, the drug {row['Drug_Name']} \"\n",
    "        f\"was associated with the adverse event '{row['Adverse_Event']}' \"\n",
    "        f\"in a {row['Patient_Age']}-year-old patient. \"\n",
    "        f\"Description: {row['Description']}\"\n",
    "    )\n",
    "    knowledge_chunks.append(chunk)\n",
    "\n",
    "print(\"âœ… Data prepared into knowledge chunks.\")\n",
    "\n",
    "\n",
    "# --- 4. The LangChain Part (The new \"Lego Blocks\") ---\n",
    "# Here we'll use LangChain's components to build the RAG system.\n",
    "\n",
    "# Import the \"Lego blocks\" we need\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# BLOCK A: The Embedding Model and Vector Database\n",
    "# We tell LangChain which model to use for embeddings and create the vector store.\n",
    "print(\"ðŸ§  Initializing embedding model and vector store...\")\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_texts(texts=knowledge_chunks, embedding=embedding_function)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2}) # This will retrieve the top 2 most relevant chunks.\n",
    "print(\"âœ… Vector store is ready.\")\n",
    "\n",
    "# BLOCK B: The LLM and Prompt Template\n",
    "# We set up the Gemini model and create a template for our prompt.\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "template = \"\"\"\n",
    "System Instruction: You are a helpful AI assistant. Answer the user's question based ONLY on the context provided below.\n",
    "\n",
    "Context:\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "User's Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# BLOCK C: The RAG Chain\n",
    "# This is the magic of LangChain! We \"chain\" all our blocks together.\n",
    "# The pipe symbol `|` passes the output of one block to the input of the next.\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"ðŸ”— RAG chain created.\")\n",
    "\n",
    "\n",
    "# --- 5. Ask a Question! ---\n",
    "# Now we can just \"invoke\" our chain with a question.\n",
    "print(\"\\nðŸ¤” Asking the RAG chain a question...\")\n",
    "question = \"What is the link between Sertraline and Amenorrhea?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "print(\"\\nâœ… Final Answer:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8314379",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.4)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
